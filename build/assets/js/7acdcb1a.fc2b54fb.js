"use strict";(globalThis.webpackChunkrobotics_education_platform=globalThis.webpackChunkrobotics_education_platform||[]).push([[351],{1841(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ai-robot-control/ai-robot-bridge","title":"AI Agents \u2192 Robot Control","description":"Connecting AI Agents to ROS Controllers","source":"@site/docs/ai-robot-control/index.md","sourceDirName":"ai-robot-control","slug":"/ai-robot-control/","permalink":"/docs/ai-robot-control/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"ai-robot-bridge","title":"AI Agents \u2192 Robot Control","sidebar_position":1}}');var r=t(4848),o=t(8453);const i={id:"ai-robot-bridge",title:"AI Agents \u2192 Robot Control",sidebar_position:1},a="AI Agents \u2192 Robot Control",l={},c=[{value:"Connecting AI Agents to ROS Controllers",id:"connecting-ai-agents-to-ros-controllers",level:2},{value:"Understanding the Bridge Architecture",id:"understanding-the-bridge-architecture",level:2},{value:"Using rclpy to Publish and Subscribe",id:"using-rclpy-to-publish-and-subscribe",level:2},{value:"Publishing Commands from AI Agents",id:"publishing-commands-from-ai-agents",level:3},{value:"Receiving Robot State Information",id:"receiving-robot-state-information",level:3},{value:"Advanced AI Integration Patterns",id:"advanced-ai-integration-patterns",level:2},{value:"Reinforcement Learning Agent",id:"reinforcement-learning-agent",level:3},{value:"Example Command \u2192 Robot Movement",id:"example-command--robot-movement",level:2},{value:"Best Practices for AI-Agent Integration",id:"best-practices-for-ai-agent-integration",level:2},{value:"Summary",id:"summary",level:2}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"ai-agents--robot-control",children:"AI Agents \u2192 Robot Control"})}),"\n",(0,r.jsx)(e.h2,{id:"connecting-ai-agents-to-ros-controllers",children:"Connecting AI Agents to ROS Controllers"}),"\n",(0,r.jsx)(e.p,{children:'In this chapter, we\'ll explore how to bridge Python-based AI agents with ROS 2 controllers to enable intelligent robot behavior. This connection forms the "brain" of our robotic system, allowing AI algorithms to control physical or simulated robots.'}),"\n",(0,r.jsx)(e.h2,{id:"understanding-the-bridge-architecture",children:"Understanding the Bridge Architecture"}),"\n",(0,r.jsx)(e.p,{children:"The connection between AI agents and robot controllers typically follows this pattern:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"AI Agent (Python) \u2192 ROS 2 Publisher \u2192 Robot Controller \u2192 Physical/Simulated Robot\n"})}),"\n",(0,r.jsx)(e.p,{children:"The AI agent makes decisions based on sensor inputs and sends commands to the robot through ROS 2 topics. The robot controller receives these commands and executes them on the actual hardware or simulation."}),"\n",(0,r.jsx)(e.h2,{id:"using-rclpy-to-publish-and-subscribe",children:"Using rclpy to Publish and Subscribe"}),"\n",(0,r.jsx)(e.h3,{id:"publishing-commands-from-ai-agents",children:"Publishing Commands from AI Agents"}),"\n",(0,r.jsx)(e.p,{children:"Here's an example of how an AI agent can publish movement commands to a robot:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\n\nclass AINavigationAgent(Node):\n    def __init__(self):\n        super().__init__(\'ai_navigation_agent\')\n        \n        # Publisher for robot velocity commands\n        self.cmd_vel_publisher = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        \n        # Subscriber for laser scan data (sensor input)\n        self.scan_subscriber = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n        \n        # Timer for AI decision-making loop\n        self.timer = self.create_timer(0.1, self.ai_decision_loop)\n        \n        # Internal state\n        self.laser_data = None\n        self.linear_velocity = 0.0\n        self.angular_velocity = 0.0\n\n    def scan_callback(self, msg):\n        """Process incoming laser scan data"""\n        self.laser_data = msg.ranges\n    \n    def ai_decision_loop(self):\n        """Main AI decision-making function"""\n        if self.laser_data is None:\n            return\n            \n        # Simple obstacle avoidance algorithm\n        cmd_vel = self.simple_avoidance_algorithm()\n        \n        # Publish the command\n        self.cmd_vel_publisher.publish(cmd_vel)\n        \n    def simple_avoidance_algorithm(self):\n        """Simple AI algorithm for obstacle avoidance"""\n        msg = Twist()\n        \n        if self.laser_data:\n            # Get distances in front, left, and right\n            front_distances = self.laser_data[330:390]  # Front 60 degrees\n            left_distances = self.laser_data[60:120]    # Left 60 degrees  \n            right_distances = self.laser_data[240:300]  # Right 60 degrees\n            \n            # Calculate minimum distances\n            min_front = min(front_distances) if front_distances else float(\'inf\')\n            min_left = min(left_distances) if left_distances else float(\'inf\')\n            min_right = min(right_distances) if right_distances else float(\'inf\')\n            \n            # Simple navigation logic\n            if min_front > 1.0:  # Clear path ahead\n                msg.linear.x = 0.5  # Move forward\n                msg.angular.z = 0.0\n            elif min_left > min_right:  # Turn left is safer\n                msg.linear.x = 0.2\n                msg.angular.z = 0.5\n            else:  # Turn right is safer\n                msg.linear.x = 0.2\n                msg.angular.z = -0.5\n                \n        return msg\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = AINavigationAgent()\n    \n    try:\n        rclpy.spin(ai_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"receiving-robot-state-information",children:"Receiving Robot State Information"}),"\n",(0,r.jsx)(e.p,{children:"AI agents often need to receive state information from the robot. Here's an example of subscribing to robot odometry:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Odometry\nfrom geometry_msgs.msg import Pose, Twist\nimport math\n\nclass AILocalizationAgent(Node):\n    def __init__(self):\n        super().__init__(\'ai_localization_agent\')\n        \n        # Subscriber for robot pose\n        self.odom_subscriber = self.create_subscription(\n            Odometry,\n            \'/odom\',\n            self.odom_callback,\n            10\n        )\n        \n        # Publisher for navigation goals\n        self.goal_publisher = self.create_publisher(Pose, \'/goal_pose\', 10)\n        \n        # Internal state\n        self.current_pose = None\n        self.current_twist = None\n        \n    def odom_callback(self, msg):\n        """Process incoming odometry data"""\n        self.current_pose = msg.pose.pose\n        self.current_twist = msg.twist.twist\n        \n        # Process the data with AI algorithms\n        self.process_robot_state()\n        \n    def process_robot_state(self):\n        """AI processing of robot state"""\n        if self.current_pose:\n            x = self.current_pose.position.x\n            y = self.current_pose.position.y\n            \n            # Example: Check if robot is near a boundary\n            if abs(x) > 5.0 or abs(y) > 5.0:\n                # Send a goal back toward center\n                goal_msg = Pose()\n                goal_msg.position.x = 0.0\n                goal_msg.position.y = 0.0\n                self.goal_publisher.publish(goal_msg)\n                \n    def distance_to_goal(self, goal_x, goal_y):\n        """Calculate Euclidean distance to goal"""\n        if self.current_pose:\n            current_x = self.current_pose.position.x\n            current_y = self.current_pose.position.y\n            return math.sqrt((goal_x - current_x)**2 + (goal_y - current_y)**2)\n        return float(\'inf\')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    ai_agent = AILocalizationAgent()\n    \n    try:\n        rclpy.spin(ai_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        ai_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(e.h2,{id:"advanced-ai-integration-patterns",children:"Advanced AI Integration Patterns"}),"\n",(0,r.jsx)(e.h3,{id:"reinforcement-learning-agent",children:"Reinforcement Learning Agent"}),"\n",(0,r.jsx)(e.p,{children:"Here's an example of how a reinforcement learning agent could interface with ROS 2:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\n\nclass RLNavigationAgent(Node):\n    def __init__(self):\n        super().__init__(\'rl_navigation_agent\')\n        \n        # Publishers and subscribers\n        self.cmd_vel_publisher = self.create_publisher(Twist, \'/cmd_vel\', 10)\n        self.scan_subscriber = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.scan_callback,\n            10\n        )\n        \n        # Timer for decision making\n        self.timer = self.create_timer(0.2, self.rl_decision_loop)\n        \n        # RL agent parameters\n        self.state = None\n        self.previous_action = None\n        self.reward = 0.0\n        \n        # Initialize simple Q-table (for demonstration)\n        self.q_table = np.zeros((10, 5))  # 10 states, 5 actions\n        self.learning_rate = 0.1\n        self.discount_factor = 0.9\n        self.exploration_rate = 0.1\n\n    def scan_callback(self, msg):\n        """Convert laser scan to discrete state representation"""\n        ranges = np.array(msg.ranges)\n        ranges = np.nan_to_num(ranges, nan=10.0)  # Replace NaN with max range\n        \n        # Discretize the state based on distance readings\n        front_avg = np.mean(ranges[330:390])\n        left_avg = np.mean(ranges[60:120])\n        right_avg = np.mean(ranges[240:300])\n        \n        # Create discrete state (simplified)\n        state_idx = 0\n        if front_avg < 0.5:\n            state_idx = 1  # Very close obstacle\n        elif front_avg < 1.0:\n            state_idx = 2  # Close obstacle\n        elif front_avg < 2.0:\n            state_idx = 3  # Medium distance\n        else:\n            state_idx = 4  # Clear path\n            \n        if left_avg < 0.5:\n            state_idx += 5  # Left too close\n            \n        self.state = state_idx\n\n    def rl_decision_loop(self):\n        """RL decision making process"""\n        if self.state is None:\n            return\n            \n        # Choose action using epsilon-greedy policy\n        if np.random.random() < self.exploration_rate:\n            action = np.random.choice(5)  # Explore\n        else:\n            action = np.argmax(self.q_table[self.state])  # Exploit\n            \n        # Convert action to robot command\n        cmd_vel = self.action_to_cmd_vel(action)\n        \n        # Publish command\n        self.cmd_vel_publisher.publish(cmd_vel)\n        \n        # Store action for next iteration\n        self.previous_action = action\n\n    def action_to_cmd_vel(self, action):\n        """Map discrete action to Twist command"""\n        msg = Twist()\n        \n        if action == 0:  # Move forward\n            msg.linear.x = 0.5\n            msg.angular.z = 0.0\n        elif action == 1:  # Turn slightly left\n            msg.linear.x = 0.3\n            msg.angular.z = 0.3\n        elif action == 2:  # Turn slightly right\n            msg.linear.x = 0.3\n            msg.angular.z = -0.3\n        elif action == 3:  # Turn left\n            msg.linear.x = 0.1\n            msg.angular.z = 0.8\n        elif action == 4:  # Turn right\n            msg.linear.x = 0.1\n            msg.angular.z = -0.8\n            \n        return msg\n\ndef main(args=None):\n    rclpy.init(args=args)\n    rl_agent = RLNavigationAgent()\n    \n    try:\n        rclpy.spin(rl_agent)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        rl_agent.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(e.h2,{id:"example-command--robot-movement",children:"Example Command \u2192 Robot Movement"}),"\n",(0,r.jsx)(e.p,{children:"Here's a complete example showing how an AI agent can interpret high-level commands and convert them to robot movements:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom std_msgs.msg import String\nimport json\n\nclass CommandInterpreter(Node):\n    def __init__(self):\n        super().__init__('command_interpreter')\n        \n        # Publisher for robot movement\n        self.cmd_vel_publisher = self.create_publisher(Twist, '/cmd_vel', 10)\n        \n        # Subscriber for high-level commands\n        self.command_subscriber = self.create_subscription(\n            String,\n            '/ai_commands',\n            self.command_callback,\n            10\n        )\n        \n        self.get_logger().info('Command interpreter initialized')\n\n    def command_callback(self, msg):\n        \"\"\"Process high-level commands from AI\"\"\"\n        try:\n            command_data = json.loads(msg.data)\n            command = command_data.get('command', '')\n            \n            if command == 'move_forward':\n                self.move_forward(command_data.get('distance', 1.0))\n            elif command == 'turn_left':\n                self.turn_left(command_data.get('angle', 90))\n            elif command == 'turn_right':\n                self.turn_right(command_data.get('angle', 90))\n            elif command == 'stop':\n                self.stop_robot()\n            else:\n                self.get_logger().warning(f'Unknown command: {command}')\n                \n        except json.JSONDecodeError:\n            self.get_logger().error(f'Invalid JSON command: {msg.data}')\n\n    def move_forward(self, distance):\n        \"\"\"Move robot forward by specified distance\"\"\"\n        msg = Twist()\n        msg.linear.x = 0.5  # Speed\n        # In a real implementation, you'd integrate over time to achieve distance\n        self.cmd_vel_publisher.publish(msg)\n        self.get_logger().info(f'Moving forward {distance} meters')\n\n    def turn_left(self, angle):\n        \"\"\"Turn robot left by specified angle\"\"\"\n        msg = Twist()\n        msg.angular.z = 0.5  # Angular speed\n        self.cmd_vel_publisher.publish(msg)\n        self.get_logger().info(f'Turning left {angle} degrees')\n\n    def turn_right(self, angle):\n        \"\"\"Turn robot right by specified angle\"\"\"\n        msg = Twist()\n        msg.angular.z = -0.5  # Angular speed\n        self.cmd_vel_publisher.publish(msg)\n        self.get_logger().info(f'Turning right {angle} degrees')\n\n    def stop_robot(self):\n        \"\"\"Stop robot movement\"\"\"\n        msg = Twist()\n        msg.linear.x = 0.0\n        msg.angular.z = 0.0\n        self.cmd_vel_publisher.publish(msg)\n        self.get_logger().info('Robot stopped')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    interpreter = CommandInterpreter()\n    \n    try:\n        rclpy.spin(interpreter)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        interpreter.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(e.h2,{id:"best-practices-for-ai-agent-integration",children:"Best Practices for AI-Agent Integration"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"State Management"}),": Keep track of the robot's state and environment to make informed decisions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Safety Checks"}),": Always implement safety mechanisms to prevent dangerous robot behavior"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Modular Design"}),": Separate perception, decision-making, and action components"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Error Handling"}),": Handle sensor failures and communication issues gracefully"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Performance"}),": Optimize AI algorithms for real-time execution"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(e.p,{children:"In this chapter, we explored how to connect AI agents with ROS 2 robot controllers:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Using publishers to send commands from AI agents"}),"\n",(0,r.jsx)(e.li,{children:"Using subscribers to receive sensor data for AI decision-making"}),"\n",(0,r.jsx)(e.li,{children:"Implementing different AI approaches (rule-based, reinforcement learning)"}),"\n",(0,r.jsx)(e.li,{children:"Converting high-level commands to robot movements"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"These techniques enable sophisticated robot behaviors driven by artificial intelligence, forming the core of autonomous robotic systems."})]})}function d(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(m,{...n})}):m(n)}},8453(n,e,t){t.d(e,{R:()=>i,x:()=>a});var s=t(6540);const r={},o=s.createContext(r);function i(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:i(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);